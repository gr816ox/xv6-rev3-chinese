## 3.2 Kernel  address space

​	Xv6 为每个进程维护一个页表，用于描述该进程的用户地址空间，此外还有一个单独的页表用于描述内核的地址空间。内核会配置其地址空间的布局，以便在可预测的虚拟地址上访问物理内存和各种硬件资源。图 3.3 展示了这种布局如何将内核的虚拟地址映射到物理地址。文件 `kernel/memlayout.h` 中声明了 xv6 内核内存布局所使用的常量。

![image-20250728094008013](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250728094008013.png)

​	QEMU 模拟了一台计算机，其中包含从物理地址 0x80000000 开始的 RAM（物理内存），并至少延续到 0x88000000，xv6 将这个结束地址称为 PHYSTOP。QEMU 的模拟还包括一些 I/O 设备，例如磁盘接口。QEMU 将这些设备接口以**内存映射控制寄存器**的形式暴露给软件，这些寄存器位于物理地址空间中低于 0x80000000 的位置。内核可以通过读写这些特殊的物理地址与设备进行交互；这样的读写操作是与设备硬件通信，而不是与 RAM 通信。第 4 章将介绍 xv6 如何与设备交互。

​	有一些内核虚拟地址并不是直接映射的：

- **跳板页（trampoline page）**：它被映射在虚拟地址空间的顶部；用户页表也具有相同的映射。第 4 章会讨论跳板页的作用，但在这里我们已经可以看到页表的一个有趣用途：一个物理页面（存放跳板代码）在内核的虚拟地址空间中被映射了两次——一次是在虚拟地址空间的顶部，另一次是通过直接映射。

- **内核栈页面（kernel stack pages）**：每个进程都有自己的内核栈，并且这些栈被映射在较高的虚拟地址处，这样在其下方就可以保留一个未映射的保护页（guard page）。这个保护页的页表项（PTE）是无效的（即 PTE_V 未设置），因此如果内核栈发生溢出，很可能会触发异常并导致内核崩溃（panic）。如果没有保护页，栈溢出就会覆盖其他内核内存，从而导致错误的操作行为。相比之下，引发崩溃是更好的选择。

​	虽然内核通过高地址映射来使用这些栈，但它们也可以通过直接映射的地址被内核访问。另一种设计可能只使用直接映射，并在直接映射的地址处使用这些栈。然而，在这种安排下，要提供保护页就需要取消映射那些原本指向物理内存的虚拟地址，这会使这些物理内存难以使用。

​	内核对跳板页以及内核代码段（kernel text）的页面使用权限 PTE_R 和 PTE_X 进行映射，表示内核可以从这些页面读取数据并执行指令。对于其他页面，内核使用权限 PTE_R 和 PTE_W 进行映射，使其可以读取和写入这些页面中的内存。而保护页的映射则是无效的（invalid）。



##  3.3 Code: creating an address space

### 3.3 代码：创建地址空间

​	大多数用于操作地址空间和页表的 xv6 代码都位于 `vm.c` 文件中（`kernel/vm.c:1`）。核心的数据结构是 `pagetable_t`，它实际上是一个指向 RISC-V 根页表页面的指针；`pagetable_t` 可以是内核页表，也可以是某个进程的页表。核心函数包括 `walk`（用于查找某个虚拟地址对应的 PTE）和 `mappages`（用于安装新的映射）。以 `kvm` 开头的函数用于操作内核页表；以 `uvm` 开头的函数用于操作用户页表；其他函数则两者都适用。`copyout` 和 `copyin` 用于在系统调用参数提供的用户虚拟地址之间复制数据；它们也位于 `vm.c` 中，因为需要显式地翻译这些地址才能找到对应的物理内存。

​	在启动序列的早期阶段，`main` 函数调用 `kvminit`（`kernel/vm.c:54`）来使用 `kvmmake`（`kernel/vm.c:20`）创建内核的页表。这个调用发生在 xv6 启用 RISC-V 分页机制之前，因此地址直接指向物理内存。`kvmmake` 首先分配一页物理内存来存放根页表页面。然后它调用 `kvmmap` 来安装内核所需的转换映射。这些映射包括内核的指令和数据、从 0 到 PHYSTOP 的物理内存，以及实际上是设备的内存范围。`proc_mapstacks`（`kernel/proc.c:33`）为每个进程分配一个内核栈。它调用 `kvmmap` 将每个栈映射到由 `KSTACK` 生成的虚拟地址上，这样就在栈下方留出了无效的栈保护页的空间。

​	`kvmmap`（`kernel/vm.c:132`）调用 `mappages`（`kernel/vm.c:143`），后者为一段虚拟地址范围安装映射到相应物理地址范围的 PTE。它以页面间隔为单位，分别为范围内的每个虚拟地址执行此操作。对于每个要映射的虚拟地址，`mappages` 调用 `walk` 来找到该地址的 PTE 地址。然后它初始化 PTE，保存相关的物理页号、所需的权限（PTE_W、PTE_X 和/或 PTE_R），以及设置 PTE_V 来标记 PTE 为有效（`kernel/vm.c:158`）。

​	`walk`（`kernel/vm.c:86`）模拟 RISC-V 分页硬件来查找虚拟地址的 PTE（见图 3.2）。`walk` 每次下降 9 位来遍历三级页表。它使用每级的 9 位虚拟地址来找到下一级页表或最终页面的 PTE（`kernel/vm.c:92`）。如果 PTE 无效，则说明所需的页面尚未分配；如果设置了 `alloc` 参数，`walk` 会分配一个新的页表页面并将它的物理地址放入 PTE 中。它返回树中最底层 PTE 的地址（`kernel/vm.c:102`）。

​	上述代码依赖于物理内存被直接映射到内核虚拟地址空间中。例如，当 `walk` 下降到页表的各级时，它从 PTE 中提取下一级页表的（物理）地址（`kernel/vm.c:94`），然后将该地址作为虚拟地址使用来获取下一级的 PTE（`kernel/vm.c:92`）。

`	main` 调用 `kvminithart`（`kernel/vm.c:62`）来安装内核页表。它将根页表页面的物理地址写入 `satp` 寄存器。此后 CPU 将使用内核页表来翻译地址。由于内核使用恒等映射，现在下一条指令的虚拟地址将映射到正确的物理内存地址。

​	每个 RISC-V CPU 都在 Translation Look-aside Buffer (TLB) 中缓存页表条目，当 xv6 更改页表时，必须告诉 CPU 使相应的缓存 TLB 条目失效。如果不这样做，那么在某个时刻 TLB 可能会使用旧的缓存映射，指向一个在此期间已被分配给其他进程的物理页面，结果某个进程就可能能够篡改其他进程的内存。RISC-V 提供了 `sfence.vma` 指令来刷新当前 CPU 的 TLB。xv6 在 `kvminithart` 中重新加载 `satp` 寄存器后执行 `sfence.vma`，并在切换到用户页表返回用户空间之前的跳板代码中执行（`kernel/trampoline.S:89`）。

​	在更改 `satp` 之前也需要执行 `sfence.vma`，以便等待所有未完成的加载和存储操作完成。这种等待确保了之前的页表更新已经完成，并确保之前的加载和存储操作使用旧的页表，而不是新的页表。

​	为了避免刷新整个 TLB，RISC-V CPU 可能支持地址空间标识符（ASID）[3]。内核可以只刷新特定地址空间的 TLB 条目。xv6 没有使用这个特性。



## 3.6 Process address space

​	每个进程都有独立的页表，当 xv6 在进程之间切换时，也会切换页表。图 3.4 比图 2.3 更详细地展示了进程的地址空间。一个进程的用户内存从虚拟地址 0 开始，最多可增长到 MAXVA（kernel/riscv.h:360），理论上允许一个进程访问 256 GB 的内存。

​	一个进程的地址空间由多个页面组成，包括存放程序代码的页面（xv6 使用 PTE_R、PTE_X 和 PTE_U 权限映射）、存放程序预初始化数据的页面、一个用于栈的页面，以及用于堆的页面。xv6 使用 PTE_R、PTE_W 和 PTE_U 权限来映射数据、栈和堆。

​	在用户地址空间中使用权限控制是一种常见的增强进程安全性的技术。如果程序代码段被映射为可写（PTE_W），那么进程可能会意外修改自身的程序代码；例如，编程错误可能导致程序向空指针（地址 0）写入数据，从而修改位于地址 0 处的指令，然后继续运行，可能造成更严重的破坏。为了立即检测此类错误，xv6 将代码段以不可写的方式映射（不设置 PTE_W）；如果程序意外尝试向地址 0 写入数据，硬件将拒绝执行该写操作并触发页错误（参见第 4.6 节）。随后内核会终止该进程，并输出一条提示信息，帮助开发者定位问题。

​	类似地，通过将数据段映射为不可执行（不设置 PTE_X），用户程序就不会意外跳转到数据区域的某个地址并开始执行该处的代码。

​	在实际应用中，仔细设置内存权限以增强进程安全性，也有助于防御安全攻击。攻击者可能会向程序（例如 Web 服务器）提供精心构造的输入，触发程序中的漏洞，企图将该漏洞转化为可利用的攻击手段 [14]。仔细设置内存权限，以及诸如随机化用户地址空间布局等其他技术，都能使此类攻击更加困难。

​	栈仅占用一个页面，图中显示的是 exec 创建时栈的初始内容。命令行参数的字符串以及指向这些字符串的指针数组位于栈的最顶端。其下方是一些值，使得程序可以从 main 函数开始执行，就像函数 `main(argc, argv)` 刚被调用一样。

​	为了检测用户栈溢出已分配的栈内存，xv6 在栈下方设置了一个不可访问的“保护页”（guard page），方法是清除该页表项的 PTE_U 标志。当用户栈溢出并尝试访问栈下方的地址时，由于保护页对用户模式下的程序不可访问，硬件将产生页错误异常。在真实的操作系统中，可能会选择在栈溢出时自动为用户栈分配更多内存。

​	当进程向 xv6 请求更多用户内存时，xv6 会扩展该进程的堆。xv6 首先使用`kalloc` 分配物理页面，然后在进程的页表中添加指向这些新物理页面的页表项（PTE），并设置这些 PTE 中的 PTE_W、PTE_R、PTE_U 和 PTE_V 标志。大多数进程并不会使用整个用户地址空间；xv6 会将未使用的页表项中的 PTE_V 标志保持清除状态。

​	我们在这里可以看到页表的一些良好应用实例。首先，不同进程的页表将用户虚拟地址映射到不同的物理内存页面，从而确保每个进程拥有独立的用户内存空间。其次，每个进程看到的内存是始于虚拟地址 0 的连续地址空间，而其实际物理内存可以是不连续的。第三，内核在用户地址空间的顶部映射了一个包含“跳板”（trampoline）代码的页面（不设置 PTE_U），因此这一个物理页面出现在所有进程的地址空间中，但只能由内核使用。



## 3.7 Code：sbrk

​	`sbrk` 是进程用于缩小或扩大其内存空间的系统调用，该系统调用由函数` growproc` 实现（kernel/proc.c:260）。`growproc`根据参数 n 的正负，调用` uvmalloc` 或 `uvmdealloc`：若 n 为正，则扩展内存；若 n 为负，则缩小内存。`uvmalloc`（kernel/vm.c:226）通过 `kalloc` 分配物理内存，并使用 `mappages` 函数将相应的页表项（PTE）添加到用户页表中，完成虚拟地址到物理地址的映射。`uvmdealloc` 则调用 `uvmunmap`（kernel/vm.c:171），后者通过 `walk` 函数在页表中查找对应的 PTE，并使用 `kfree` 释放这些 PTE 所指向的物理内存。

​	xv6 不仅使用进程的页表来告诉硬件如何进行用户虚拟地址到物理地址的映射，还将页表作为记录该进程所分配物理内存页的唯一依据。正因如此，在释放用户内存（如 `uvmunmap` 中）时，必须检查用户页表，以确定哪些物理页面需要被释放。



## 3.8 Code：exec

​	exec 是一个系统调用，它用从文件中读取的数据替换进程的用户地址空间，这个文件被称为二进制文件或可执行文件。二进制文件通常是编译器和链接器的输出，包含机器指令和程序数据。exec（`kernel/exec.c:23`）使用 namei（`kernel/exec.c:36`）打开指定的二进制文件路径，namei 将在第 8 章中解释。然后，它读取 ELF 头部。xv6 的二进制文件采用广泛使用的 ELF 格式，定义在（`kernel/elf.h`）中。ELF 二进制文件由一个 ELF 头部 struct elfhdr（`kernel/elf.h:6`）组成，后面跟着一系列程序段头部 struct proghdr（`kernel/elf.h:25`）。每个 proghdr 描述了必须加载到内存中的应用程序段；xv6 程序有两个程序段头部：一个用于指令，一个用于数据。

​	第一步是快速检查文件是否可能包含 ELF 二进制文件。ELF 二进制文件以四个字节的"魔数" 0x7F, 'E', 'L', 'F' 或 ELF_MAGIC（`kernel/elf.h:3`）开头。如果 ELF 头部有正确的魔数，exec 就假设二进制文件格式正确。exec 使用 proc_pagetable（`kernel/exec.c:49`）分配一个新的没有用户映射的页表，使用 uvmalloc（`kernel/exec.c:65`）为每个 ELF 段分配内存，并使用 loadseg（`kernel/exec.c:10`）将每个段加载到内存中。loadseg 使用 walkaddr 找到分配内存的物理地址来写入 ELF 段的每个页面，并使用 readi 从文件中读取。

​	/init（第一个通过 exec 创建的用户程序）的程序段头部如下所示：

​	我们看到文本段应该在内存的虚拟地址 0x0 处加载（没有写权限），内容来自文件中偏移量 0x1000 处。我们还看到数据应该在地址 0x1000 处加载，这在页面边界上，并且没有可执行权限。

​	程序段头部的 filesz 可能小于 memsz，表示它们之间的间隙应该用零填充（用于 C 全局变量）而不是从文件中读取。对于 /init，数据 filesz 是 0x10 字节，memsz 是 0x30 字节，因此 uvmalloc 分配足够的物理内存来容纳 0x30 字节，但只从 /init 文件中读取 0x10 字节。

​	现在 exec 分配并初始化用户栈。它只分配一个栈页面。exec 逐个将参数字符串复制到栈顶，在 ustack 中记录指向它们的指针。它在将传递给 main 的 argv 列表末尾放置一个空指针。ustack 中的前三个条目是假的返回程序计数器、argc 和 argv 指针。

​	exec 在栈页面下方放置一个不可访问的页面，这样尝试使用超过一个页面的程序将会出现错误。这个不可访问的页面也允许 exec 处理过大的参数；在这种情况下，exec 用来将参数复制到栈的 copyout（`kernel/vm.c:352`）函数会注意到目标页面不可访问，并返回 -1。

​	在准备新内存镜像期间，如果 exec 检测到错误（如无效的程序段），它会跳转到标签 bad，释放新镜像，并返回 -1。exec 必须等到确定系统调用会成功后才能释放旧镜像：如果旧镜像消失了，系统调用就无法向它返回 -1。exec 中的唯一错误情况发生在镜像创建期间。一旦镜像完成，exec 就可以提交到新页表（`kernel/exec.c:125`）并释放旧页表（`kernel/exec.c:129`）。

​	exec 将 ELF 文件中的字节加载到 ELF 文件指定的内存地址。用户或进程可以在 ELF 文件中放置任何他们想要的地址。因此 exec 是有风险的，因为 ELF 文件中的地址可能指向内核，无论是意外还是故意。对一个不小心的内核来说，后果可能从崩溃到恶意破坏内核的隔离机制（即安全漏洞）不等。xv6 执行许多检查来避免这些风险。例如 if(ph.vaddr + ph.memsz < ph.vaddr) 检查总和是否会溢出 64 位整数。危险在于用户可以构造一个 ELF 二进制文件，其中 ph.vaddr 指向用户选择的地址，而 ph.memsz 足够大，使得总和溢出到 0x1000，这看起来像是一个有效值。在早期版本的 xv6 中，用户地址空间也包含内核（但在用户模式下不可读/写），用户可以选择对应内核内存的地址，从而将数据从 ELF 二进制文件复制到内核中。在 RISC-V 版本的 xv6 中不会发生这种情况，因为内核有自己独立的页表；loadseg 加载到进程的页表中，而不是内核的页表中。

​	内核开发人员很容易遗漏关键检查，而现实世界的内核长期以来都有缺少检查的历史，这些检查的缺失可能被用户程序利用来获得内核权限。xv6 可能没有完全验证提供给内核的用户级数据，恶意用户程序可能能够利用这一点来绕过 xv6 的隔离机制。



# Chapter 4

#  Traps and system calls

​	有三种事件会导致 CPU 暂停正常指令执行，并强制将控制权转移到处理该事件的特殊代码。第一种情况是系统调用，当用户程序执行 ecall 指令来请求内核为它做某事时发生。第二种情况是异常：指令（用户或内核）做了某些非法操作，比如除零或使用无效的虚拟地址。第三种情况是设备中断，当设备发出需要关注的信号时发生，例如当磁盘硬件完成读写请求时。

​	本书使用"陷阱"（trap）作为这些情况的通用术语。通常在陷阱发生时正在执行的代码之后需要恢复执行，并且不应该需要知道发生了任何特殊的事情。也就是说，我们通常希望陷阱是透明的；这对于设备中断尤其重要，因为被中断的代码通常不会预期到中断的发生。通常的序列是：陷阱强制将控制权转移到内核；内核保存寄存器和其他状态以便执行可以恢复；内核执行适当的处理程序代码（例如，系统调用实现或设备驱动程序）；内核恢复保存的状态并从陷阱返回；原始代码从它中断的地方继续执行。

​	xv6 在内核中处理所有陷阱；陷阱不会传递给用户代码。在内核中处理系统调用是很自然的。对于中断来说也是合理的，因为隔离要求只有内核被允许使用设备，并且因为内核是方便的机制来在多个进程之间共享设备。对于异常来说也是合理的，因为 xv6 通过杀死违规程序来响应来自用户空间的所有异常。

​	xv6 陷阱处理分为四个阶段：RISC-V CPU 执行的硬件操作，一些为内核 C 代码准备路径的汇编指令，决定如何处理陷阱的 C 函数，以及系统调用或设备驱动服务例程。虽然三种陷阱类型之间的共性表明内核可以用单一代码路径处理所有陷阱，但实际上为三种不同情况使用单独代码是很方便的：来自用户空间的陷阱、来自内核空间的陷阱，以及定时器中断。处理陷阱的内核代码（汇编或 C）通常被称为处理程序；处理程序的第一条指令通常用汇编语言编写（而不是 C 语言），有时被称为向量。

好的，这是您提供的文本内容的中文翻译：

## **4.1 RISC-V 陷阱机制**

每个 RISC-V CPU 都有一组控制寄存器，内核可以写入这些寄存器来告诉 CPU 如何处理陷阱，内核也可以读取这些寄存器来了解发生的陷阱。完整的细节在 RISC-V 文档中 [3]。`riscv.h` (kernel/riscv.h:1) 包含了 xv6 使用的定义。以下是最重要的寄存器的概述：

*   **stvec**：内核在此写入其陷阱处理程序的地址；RISC-V 跳转到 `stvec` 中的地址来处理陷阱。
*   **sepc**：当陷阱发生时，RISC-V 将程序计数器（pc）保存在这里（因为 pc 随后会被 `stvec` 的值覆盖）。`sret`（从陷阱返回）指令将 `sepc` 复制到 pc。内核可以写 `sepc` 来控制 `sret` 去往何处。
*   **scause**：RISC-V 在这里放入一个数字，用来描述陷阱的原因。
*   **sscratch**：陷阱处理程序代码使用 `sscratch` 来帮助它避免在保存用户寄存器之前覆盖它们。
*   **sstatus**：`sstatus` 中的 SIE 位控制设备中断是否启用。如果内核清除了 SIE，RISC-V 将推迟设备中断，直到内核设置 SIE。SPP 位指示陷阱是来自用户模式还是监管模式，并控制 `sret` 返回到哪种模式。

上述寄存器与在监管模式下处理的陷阱相关，并且在用户模式下无法读取或写入。还有一组类似的控制寄存器用于在机器模式下处理的陷阱；xv6 仅在定时器中断的特殊情况下使用它们。多核芯片上的每个 CPU 都有自己的这组寄存器，并且在任何给定时间可能有多个 CPU 正在处理陷阱。

当需要强制执行陷阱时，RISC-V 硬件会为所有陷阱类型（定时器中断除外）执行以下操作：

1.  如果陷阱是设备中断，并且 `sstatus` 的 SIE 位被清除，则不执行以下任何操作。
2.  通过清除 `sstatus` 中的 SIE 位来禁用中断。
3.  将 pc 复制到 `sepc`。
4.  在 `sstatus` 的 SPP 位中保存当前模式（用户或监管）。
5.  设置 `scause` 以反映陷阱的原因。
6.  将模式设置为监管模式。
7.  将 `stvec` 复制到 pc。
8.  开始在新的 pc 处执行。

请注意，CPU 不会切换到内核页表，不会切换到内核中的堆栈，也不会保存除 pc 之外的任何寄存器。内核软件必须执行这些任务。CPU 在陷阱期间执行最少工作的原因之一是为了给软件提供灵活性；例如，某些操作系统在某些情况下省略页表切换以提高陷阱性能。

值得思考的是，是否可以省略上述列出的任何步骤，或许是为了寻求更快的陷阱。虽然在某些情况下更简单的序列可以工作，但通常省略许多步骤将是危险的。例如，假设 CPU 没有切换程序计数器。那么来自用户空间的陷阱可能会在仍然运行用户指令的同时切换到监管模式。这些用户指令可能会破坏用户/内核隔离，例如通过修改 `satp` 寄存器使其指向允许访问所有物理内存的页表。因此，CPU 切换到内核指定的指令地址（即 `stvec`）是重要的。

## **4.2 来自用户空间的陷阱**

Xv6 根据陷阱是在内核还是在用户代码中执行时发生而不同地处理陷阱。这里是来自用户代码的陷阱的故事；第 4.5 节描述了来自内核代码的陷阱。

当用户程序执行系统调用（`ecall` 指令）、执行非法操作或设备中断时，可能会在用户空间执行时发生陷阱。来自用户空间的陷阱的高级路径是 `uservec` (kernel/trampoline.S:21)，然后是 `usertrap` (kernel/trap.c:37)；返回时是 `usertrapret` (kernel/trap.c:90)，然后是 `userret` (kernel/trampoline.S:101)。

xv6 陷阱处理设计的一个主要限制是 RISC-V 硬件在强制执行陷阱时不会切换页表。这意味着 `stvec` 中的陷阱处理程序地址必须在用户页表中具有有效的映射，因为这是陷阱处理代码开始执行时生效的页表。此外，xv6 的陷阱处理代码需要切换到内核页表；为了能够在切换后继续执行，内核页表也必须对 `stvec` 指向的处理程序具有映射。

xv6 使用一个**蹦床页 (trampoline page)** 来满足这些要求。蹦床页包含 `uservec`，即 `stvec` 指向的 xv6 陷阱处理代码。蹦床页映射在每个进程的页表中的地址 `TRAMPOLINE`，该地址位于虚拟地址空间的顶部，因此它将在程序自己使用的内存之上。蹦床页也映射在内核页表中的地址 `TRAMPOLINE`。参见图 2.3 和图 3.3。

因为蹦床页映射在用户页表中，并且没有 `PTE_U` 标志，所以陷阱可以在监管模式下开始在那里执行。因为蹦床页在内核地址空间中映射在相同的地址，所以陷阱处理程序在切换到内核页表后可以继续执行。

`uservec` 陷阱处理程序的代码在 `trampoline.S` (kernel/trampoline.S:21) 中。当 `uservec` 开始时，所有 32 个寄存器都包含被中断的用户代码拥有的值。这 32 个值需要保存在内存中的某个地方，以便在陷阱返回用户空间时可以恢复它们。将值存储到内存需要使用寄存器来保存地址，但在此时没有通用寄存器可用！幸运的是，RISC-V 提供了 `sscratch` 寄存器作为帮助。`uservec` 开头的 `csrw` 指令将 `a0` 保存到 `sscratch`。现在 `uservec` 有了一个寄存器 (`a0`) 可以使用。

`uservec` 的下一个任务是保存 32 个用户寄存器。内核为每个进程分配一个内存页，用于 `trapframe` 结构，该结构（除其他外）有空间保存 32 个用户寄存器（kernel/proc.h:43）。因为 `satp` 仍然指向用户页表，`uservec` 需要 `trapframe` 映射在用户地址空间中。xv6 在每个进程的用户页表中将该进程的 `trapframe` 映射在虚拟地址 `TRAPFRAME`；`TRAPFRAME` 位于 `TRAMPOLINE` 下方一点。进程的 `p->trapframe` 也指向 `trapframe`，尽管它指向物理地址，以便内核可以通过内核页表使用它。

因此，`uservec` 将地址 `TRAPFRAME` 加载到 `a0` 中，并将所有用户寄存器保存在那里，包括从 `sscratch` 读回的用户 `a0`。陷阱帧包含当前进程的内核堆栈地址、当前 CPU 的 `hartid`、`usertrap` 函数的地址以及内核页表的地址。`uservec` 检索这些值，将 `satp` 切换到内核页表，然后调用 `usertrap`。

`usertrap` 的工作是确定陷阱的原因，处理它，然后返回 (kernel/trap.c:37)。它首先更改 `stvec`，以便在内核中的陷阱将由 `kernelvec` 而不是 `uservec` 处理。它保存 `sepc` 寄存器（保存的用户程序计数器），因为 `usertrap` 可能会调用 `yield` 切换到另一个进程的内核线程，而该进程可能会返回到用户空间，在此过程中会修改 `sepc`。

如果陷阱是系统调用，`usertrap` 调用 `syscall` 来处理它；如果是设备中断，则调用 `devintr`；否则就是异常，内核会杀死出错的进程。在系统调用的情况下，系统调用路径会将保存的用户程序计数器加四，因为 RISC-V 在系统调用时，将程序指针指向 `ecall` 指令，但用户代码需要在后续指令处恢复执行。

在返回的路上，`usertrap` 会检查进程是否已被杀死或是否应该让出 CPU（如果此陷阱是定时器中断）。

返回用户空间的第一步是调用 `usertrapret` (kernel/trap.c:90)。此函数设置 RISC-V 控制寄存器，为将来从用户空间进行的陷阱做准备。这包括将 `stvec` 更改为指向 `uservec`，准备 `uservec` 依赖的陷阱帧字段，并将 `sepc` 设置为先前保存的用户程序计数器。

最后，`usertrapret` 调用映射在用户和内核页表中的蹦床页上的 `userret`；原因是 `userret` 中的汇编代码将切换页表。`usertrapret` 对 `userret` 的调用通过 `a0` 传递指向进程用户页表的指针 (kernel/trampoline.S:101)。`userret` 将 `satp` 切换到进程的用户页表。回想一下，用户页表映射了蹦床页和 `TRAPFRAME`，但没有映射内核中的其他任何内容。用户和内核页表中蹦床页在相同虚拟地址的映射允许 `userret` 在更改 `satp` 后继续执行。从这一点开始，`userret` 可以使用的唯一数据是寄存器内容和陷阱帧的内容。

`userret` 将 `TRAPFRAME` 地址加载到 `a0` 中，通过 `a0` 从陷阱帧恢复保存的用户寄存器，恢复保存的用户 `a0`，并执行 `sret` 以返回用户空间。

## **4.3 代码：调用系统调用**

第 2 章以 `initcode.S` 调用 `exec` 系统调用结束 (user/initcode.S:11)。让我们看看用户调用是如何传递到内核中 `exec` 系统调用实现的。

`initcode.S` 将 `exec` 的参数放在寄存器 `a0` 和 `a1` 中，并将系统调用号放在 `a7` 中。系统调用号与 `syscalls` 数组中的条目匹配，该数组是一个函数指针表 (kernel/syscall.c:107)。`ecall` 指令陷入内核，导致 `uservec`、`usertrap`，然后是 `syscall` 执行，如上所述。

`syscall` (kernel/syscall.c:132) 从陷阱帧中保存的 `a7` 中检索系统调用号，并使用它作为索引进入 `syscalls`。对于第一个系统调用，`a7` 包含 `SYS_exec` (kernel/syscall.h:8)，导致调用系统调用实现函数 `sys_exec`。

当 `sys_exec` 返回时，`syscall` 将其返回值记录在 `p->trapframe->a0` 中。这将导致原始的用户空间 `exec()` 调用返回该值，因为 RISC-V 上的 C 调用约定将返回值放在 `a0` 中。系统调用通常返回负数表示错误，返回零或正数表示成功。如果系统调用号无效，`syscall` 会打印错误并返回 -1。

## **4.4 代码：系统调用参数**

内核中的系统调用实现需要找到用户代码传递的参数。因为用户代码调用系统调用包装函数，所以参数最初放置在 RISC-V C 调用约定放置它们的位置：寄存器中。内核陷阱代码将用户寄存器保存到当前进程的陷阱帧中，内核代码可以在那里找到它们。内核函数 `argint`、`argaddr` 和 `argfd` 从陷阱帧中检索第 n 个系统调用参数，分别作为整数、指针或文件描述符。它们都调用 `argraw` 来检索适当的保存的用户寄存器 (kernel/syscall.c:34)。

一些系统调用传递指针作为参数，内核必须使用这些指针来读取或写入用户内存。例如，`exec` 系统调用向内核传递一个指针数组，这些指针引用用户空间中的字符串参数。这些指针带来了两个挑战。首先，用户程序可能有错误或恶意，可能会向内核传递无效指针或旨在欺骗内核访问内核内存而不是用户内存的指针。其次，xv6 内核页表映射与用户页表映射不同，因此内核无法使用普通指令从用户提供的地址加载或存储。

内核实现了可以安全地在用户提供的地址之间传输数据的函数。`fetchstr` 就是一个例子 (kernel/syscall.c:25)。文件系统调用（如 `exec`）使用 `fetchstr` 从用户空间检索字符串文件名参数。`fetchstr` 调用 `copyinstr` 来完成繁重的工作。`copyinstr` (kernel/vm.c:403) 从用户页表 `pagetable` 中的虚拟地址 `srcva` 复制最多 `max` 字节到 `dst`。由于 `pagetable` 不是当前页表，`copyinstr` 使用 `walkaddr`（调用 `walk`）在 `pagetable` 中查找 `srcva`，产生物理地址 `pa0`。内核将每个物理 RAM 地址映射到相应的内核虚拟地址，因此 `copyinstr` 可以直接将字符串字节从 `pa0` 复制到 `dst`。`walkaddr` (kernel/vm.c:109) 检查用户提供的虚拟地址是否是进程用户地址空间的一部分，因此程序无法欺骗内核读取其他内存。一个类似的函数 `copyout` 将数据从内核复制到用户提供的地址。

## **4.5 来自内核空间的陷阱**

xv6 根据执行的是用户代码还是内核代码，以不同的方式配置 CPU 陷阱寄存器。当内核在 CPU 上执行时，内核将 `stvec` 指向 `kernelvec` (kernel/kernelvec.S:12) 的汇编代码。由于 xv6 已经在内核中，`kernelvec` 可以依赖于 `satp` 被设置为内核页表，并且堆栈指针引用有效的内核堆栈。

`kernelvec` 将所有 32 个寄存器推入堆栈，以便稍后可以恢复它们，从而使被中断的内核代码可以不受干扰地恢复。`kernelvec` 将寄存器保存在被中断的内核线程的堆栈上，这是有道理的，因为寄存器值属于该线程。如果陷阱导致切换到不同的线程，这一点尤其重要——在这种情况下，陷阱实际上将从新线程的堆栈返回，将被中断线程的保存寄存器安全地留在其堆栈上。

`kernelvec` 在保存寄存器后跳转到 `kerneltrap` (kernel/trap.c:135)。`kerneltrap` 为两种类型的陷阱做好了准备：设备中断和异常。它调用 `devintr` (kernel/trap.c:178) 来检查和处理前者。如果陷阱不是设备中断，那它一定是异常，如果发生在 xv6 内核中，这总是一个致命错误；内核调用 `panic` 并停止执行。

如果 `kerneltrap` 是由于定时器中断而被调用，并且正在运行进程的内核线程（而不是调度程序线程），`kerneltrap` 会调用 `yield` 来让其他线程有机会运行。在某个时候，这些线程中的一个会 `yield`，让我们的线程及其 `kerneltrap` 恢复执行。第 7 章解释了 `yield` 中发生了什么。

当 `kerneltrap` 的工作完成后，它需要返回到被陷阱中断的任何代码。因为 `yield` 可能会扰乱 `sepc` 和 `sstatus` 中的先前模式，`kerneltrap` 在开始时保存了它们。现在它恢复这些控制寄存器并返回到 `kernelvec` (kernel/kernelvec.S:50)。`kernelvec` 从堆栈中弹出保存的寄存器并执行 `sret`，它将 `sepc` 复制到 pc 并恢复被中断的内核代码。

值得思考的是，如果 `kerneltrap` 由于定时器中断而调用 `yield`，陷阱返回是如何发生的。当 CPU 从用户空间进入内核时，xv6 会将该 CPU 的 `stvec` 设置为 `kernelvec`；您可以在 `usertrap` (kernel/trap.c:29) 中看到这一点。有一个时间窗口，内核已经开始执行，但 `stvec` 仍然设置为 `uservec`，在此期间不发生设备中断至关重要。幸运的是，RISC-V 在开始处理陷阱时总是禁用中断，而 xv6 直到设置 `stvec` 后才再次启用它们。

## **4.6 页面错误异常**

xv6 对异常的响应相当乏味：如果用户空间发生异常，内核会杀死出错的进程。如果在内核中发生异常，内核会 `panic`。真正的操作系统通常会以更有趣的方式响应。例如，许多内核使用页面错误来实现写时复制 (COW) `fork`。

为了说明写时复制 `fork`，请考虑第 3 章中描述的 xv6 的 `fork`。`fork` 使得子进程的初始内存内容与 `fork` 时的父进程相同。xv6 通过 `uvmcopy` (kernel/vm.c:306) 实现 `fork`，它为子进程分配物理内存并将父进程的内存复制到其中。如果父进程和子进程可以共享父进程的物理内存，这会更高效。然而，直接实现这一点将不起作用，因为它会导致父进程和子进程通过写入共享堆栈和堆来相互干扰执行。

通过适当使用页表权限和页面错误，父进程和子进程可以安全地共享物理内存。当使用没有页表映射的虚拟地址，或者映射的 PTE_V 标志被清除，或者映射的权限位（PTE_R、PTE_W、PTE_X、PTE_U）禁止尝试的操作时，CPU 会引发页面错误异常。RISC-V 区分三种页面错误：加载页面错误（当加载指令无法转换其虚拟地址时）、存储页面错误（当存储指令无法转换其虚拟地址时）和指令页面错误（当程序计数器中的地址无法转换时）。`scause` 寄存器指示页面错误的类型，`stval` 寄存器包含无法转换的地址。

COW `fork` 的基本计划是让父进程和子进程最初共享所有物理页面，但每个进程都将其映射为只读（清除 PTE_W 标志）。父进程和子进程都可以从共享的物理内存中读取。如果其中任何一个写入给定页面，RISC-V CPU 会引发页面错误异常。内核的陷阱处理程序通过分配一个新的物理内存页面并将其复制到故障地址映射到的物理页面中来响应。内核更改故障进程页表中的相关 PTE，使其指向副本并允许写入和读取，然后在导致故障的指令处恢复故障进程。由于 PTE 允许写入，重新执行的指令将不会出现故障。

写时复制需要簿记来帮助决定何时可以释放物理页面，因为每个页面可以根据 `fork`、页面错误、`exec` 和退出的历史由不同数量的页表引用。这种簿记允许一个重要的优化：如果一个进程发生存储页面错误并且物理页面仅从该进程的页表引用，则不需要复制。写时复制使 `fork` 更快，因为 `fork` 不需要复制内存。一些内存稍后必须在写入时复制，但通常大多数内存永远不需要复制。一个常见的例子是 `fork` 后跟 `exec`：`fork` 后可能会写入几页，但随后子进程的 `exec` 会释放从父进程继承的大部分内存。写时复制 `fork` 消除了复制此内存的需要。此外，COW `fork` 是透明的：应用程序无需修改即可从中受益。

除了 COW `fork` 之外，页表和页面错误的组合还开辟了广泛的有趣可能性。另一个广泛使用的功能称为延迟分配，它有两个部分。首先，当应用程序通过调用 `sbrk` 请求更多内存时，内核会记录大小的增加，但不会分配物理内存，也不会为新的虚拟地址范围创建 PTE。其次，在这些新地址之一上发生页面错误时，内核会分配一个物理内存页面并将其映射到页表中。与 COW `fork` 一样，内核可以透明地实现延迟分配。由于应用程序经常请求比它们需要的更多的内存，延迟分配是双赢的：对于应用程序从未使用的页面，内核根本不需要做任何工作。此外，如果应用程序要求将地址空间增长很多，那么没有延迟分配的 `sbrk` 代价很高：如果应用程序请求千兆字节的内存，内核必须分配并清零 262,144 个 4096 字节的页面。延迟分配允许将此成本分散到时间上。

另一方面，延迟分配会产生页面错误的额外开销，这涉及内核/用户转换。操作系统可以通过在每次页面错误时分配一批连续页面而不是一个页面，以及通过为此类页面错误专门化内核入口/出口代码来降低此成本。

另一个广泛使用的利用页面错误的功能是按需分页。在 `exec` 中，xv6 急切地将应用程序的所有文本和数据加载到内存中。由于应用程序可能很大并且从磁盘读取很昂贵，因此这种启动成本对用户来说可能是明显的：当用户从 shell 启动一个大型应用程序时，可能需要很长时间才能看到响应。为了改善响应时间，现代内核会创建用户地址空间的页表，但将页面的 PTE 标记为无效。在页面错误时，内核从磁盘读取页面内容并将其映射到用户地址空间。与 COW `fork` 和延迟分配一样，内核可以透明地实现此功能。

在计算机上运行的程序可能需要的内存超过计算机拥有的 RAM。为了优雅地应对，操作系统可以实现磁盘分页。其思想是只将一部分用户页面存储在 RAM 中，其余部分存储在磁盘上的分页区域中。内核将对应于存储在分页区域（因此不在 RAM 中）的内存的 PTE 标记为无效。如果应用程序尝试使用已分页到磁盘的页面，应用程序将发生页面错误，并且必须将页面分页进来：内核陷阱处理程序将分配一个物理 RAM 页面，从磁盘读取页面到 RAM，并修改相关 PTE 以指向 RAM。

如果需要将页面分页进来，但没有可用的物理 RAM 会发生什么？在这种情况下，内核必须首先通过将页面分页出去或驱逐到磁盘上的分页区域来释放物理页面，并将引用该物理页面的 PTE 标记为无效。驱逐是昂贵的，因此分页在不频繁时表现最佳：如果应用程序只使用它们的内存页面的一个子集，并且子集的并集适合 RAM。此属性通常被称为具有良好的局部性引用。

与许多虚拟内存技术一样，内核通常以对应用程序透明的方式实现磁盘分页。无论硬件提供多少 RAM，计算机通常在几乎没有或没有可用物理内存的情况下运行。例如，云提供商在单台机器上复用许多客户以有效地利用其硬件成本。作为另一个例子，用户在智能手机上运行许多应用程序，而物理内存很少。在这种环境下，分配页面可能需要首先驱逐现有页面。因此，当可用物理内存稀缺时，分配是昂贵的。当可用内存稀缺时，延迟分配和按需分页特别有利。在 `sbrk` 或 `exec` 中急切地分配内存会产生额外的驱逐成本以使内存可用。此外，还有浪费急切工作的风险，因为在应用程序使用页面之前，操作系统可能已经将其驱逐。

其他结合分页和页面错误异常的功能包括自动扩展堆栈和内存映射文件。

## **4.7 现实世界**

蹦床和陷阱帧可能看起来过于复杂。一个驱动力是 RISC-V 在强制执行陷阱时故意尽可能少地做，以允许非常快速的陷阱处理的可能性，事实证明这很重要。因此，内核陷阱处理程序的前几条指令实际上必须在用户环境中执行：用户页表和用户寄存器内容。而且陷阱处理程序最初不知道有用的细节，例如正在运行的进程的身份或内核页表的地址。解决方案是可行的，因为 RISC-V 提供了受保护的地方，内核可以在进入用户空间之前在其中存放信息：`sscratch` 寄存器和指向内核内存但受缺少 `PTE_U` 保护的用户页表条目。xv6 的蹦床和陷阱帧利用了这些 RISC-V 功能。

如果内核内存映射到每个进程的用户页表中（具有适当的 PTE 权限标志），则可以消除对特殊蹦床页的需求。这也将消除从用户空间陷入内核时的页表切换需求。这反过来将允许内核中的系统调用实现利用当前进程的用户内存被映射，允许内核代码直接解引用用户指针。许多操作系统使用这些想法来提高效率。xv6 避免使用它们是为了减少由于意外使用用户指针而导致的内核安全错误的可能性，并减少确保用户和内核虚拟地址不重叠所需的一些复杂性。

生产操作系统实现了写时复制 `fork`、延迟分配、按需分页、磁盘分页、内存映射文件等。此外，生产操作系统将尝试使用所有物理内存，无论是用于应用程序还是缓存（例如，我们将在第 8.2 节中介绍的文件系统的缓冲区缓存）。在这方面，xv6 是天真的：您希望您的操作系统使用您购买的物理内存，但 xv6 不会。此外，如果 xv6 内存不足，它会向正在运行的应用程序返回错误或将其杀死，而不是例如驱逐另一个应用程序的页面。



# 第5章

# 中断与设备驱动程序

驱动程序是操作系统中用于管理特定设备的代码：它配置设备硬件，指示设备执行操作，处理由此产生的中断，并与可能正在等待设备I/O的进程进行交互。驱动程序代码可能比较棘手，因为驱动程序与其管理的设备是并发执行的。此外，驱动程序必须理解设备的硬件接口，而该接口可能很复杂且文档不全。

需要操作系统关注的设备通常可以配置为产生中断，而中断是一种陷阱。内核的陷阱处理代码会识别设备是否引发了中断，并调用驱动程序的中断处理程序；在xv6中，这种分派发生在devintr（kernel/trap.c:178）中。

许多设备驱动程序在两个上下文中执行代码：在进程的内核线程中运行的“上半部分”和在中断时执行的“下半部分”。上半部分通过系统调用（如read和write）被调用，这些调用希望设备执行I/O操作。此代码可能会要求硬件启动一个操作（例如，要求磁盘读取一个块）；然后代码等待操作完成。最终，设备完成操作并引发中断。驱动程序的中断处理程序作为下半部分，确定已完成的操作，必要时唤醒等待的进程，并告诉硬件启动任何等待的下一个操作。

## 5.1 Code: Console input

控制台驱动程序（`kernel/console.c`）是驱动程序结构的一个简单示例。控制台驱动程序通过连接到RISC-V的UART串行端口硬件接收人类输入的字符。控制台驱动程序一次累积一行输入，处理诸如`Spaceback`和`Ctrl-U`等特殊输入字符。用户进程（如shell）使用read系统调用来从控制台获取输入行。当你在QEMU中向xv6输入时，你的按键通过QEMU模拟的UART硬件传递给xv6。

驱动程序所使用的UART硬件是一个由QEMU模拟的16550芯片[13]。在真正的计算机上，16550会管理连接到终端或其他计算机的RS232串行链路。当运行QEMU时，它连接到你的键盘和显示器。

UART硬件对软件而言表现为一组内存映射的控制寄存器。也就是说，RISC-V硬件将一些物理地址连接到UART设备，因此加载和存储操作与设备硬件交互，而不是与RAM交互。UART的内存映射地址从0x10000000开始，或称为UART0（`kernel/memlayout.h:21`）。有少数几个UART控制寄存器，每个寄存器宽度为一个字节。它们相对于UART0的偏移量在（`kernel/uart.c:22`）中定义。例如，LSR寄存器包含指示是否有等待软件读取的输入字符的位。这些字符（如果有的话）可以从RHR寄存器读取。每次读取一个字符时，UART硬件会从等待字符的内部FIFO中删除该字符，并在FIFO为空时清除LSR中的“就绪”位。UART的发送硬件在很大程度上独立于接收硬件；如果软件向THR写入一个字节，UART就会发送该字节。

xv6的`main`函数调用`consoleinit`（`kernel/console.c:182`）来初始化UART硬件。此代码配置UART，使其在接收到每个输入字节时产生接收中断，以及在每次发送完一个输出字节时产生发送完成中断（`kernel/uart.c:53`）。

xv6 shell通过`init.c`（`user/init.c:19`）打开的文件描述符从控制台读取。对read系统调用的调用通过内核传递到`consoleread`（`kernel/console.c:80`）。consoleread等待输入到达（通过中断）并被缓冲在cons.buf中，将输入复制到用户空间，并（在整行到达后）返回到用户进程。如果用户尚未键入完整的一行，任何读取进程将在sleep调用中等待（`kernel/console.c:96`）（第7章解释了sleep的详细信息）。

当用户键入一个字符时，UART硬件要求RISC-V引发中断，从而激活xv6的陷阱处理程序。陷阱处理程序调用`devintr`（`kernel/trap.c:178`），它查看RISC-V的scause寄存器以发现中断来自外部设备。然后它询问一个称为PLIC[3]的硬件单元，以确定是哪个设备中断了（`kernel/trap.c:187`）。如果是UART，`devintr`将调用`uartintr`。

`uartintr`（`kernel/uart.c:176`）从UART硬件读取任何等待的输入字符，并将其传递给`consoleintr`（`kernel/console.c:136`）；它不会等待字符，因为未来的输入将引发新的中断。`consoleintr`的任务是将输入字符累积在`cons.buf`中，直到整行到达。consoleintr对退格键和其他一些字符进行特殊处理。当换行符到达时，`consoleintr`会唤醒等待的`consoleread`（如果有的话）。

一旦被唤醒，`consoleread`将观察到`cons.buf`中的完整行，将其复制到用户空间，并返回（通过系统调用机制）到用户空间。



## 5.2  Code: Console output

对连接到控制台的文件描述符的write系统调用最终会到达`uartputc`（`kernel/uart.c:87`）。设备驱动程序维护一个输出缓冲区（`uart_tx_buf`），以便写入进程不必等待UART完成发送；相反，`uartputc`将每个字符追加到缓冲区，调用`uartstart`以启动设备传输（如果尚未启动），然后返回。只有在缓冲区已满的情况下，`uartputc`才会等待。

每次UART完成发送一个字节时，它都会产生一个中断。`uartintr`调用`uartstart`，它检查设备是否真的已完成发送，并将下一个缓冲的输出字符交给设备。因此，如果一个进程向控制台写入多个字节，通常第一个字节将由`uartputc`的`uartstart`调用发送，而剩余的缓冲字节将在传输完成中断到达时由`uartintr`中的`uartstart`调用发送。

需要注意的一个通用模式是通过缓冲和中断实现设备活动与进程活动的解耦。即使没有进程等待读取，控制台驱动程序也可以处理输入；后续的读取操作将看到输入。同样，进程可以在不等待设备的情况下发送输出。这种解耦可以通过允许进程与设备I/O并发执行来提高性能，当设备较慢（如UART）或需要立即关注（如回显键入的字符）时尤其重要。这个想法有时被称为I/O并发。

## 5.3 驱动程序中的并发

你可能已经注意到在`consoleread`和`consoleintr`中的`acquire`调用。这些调用获取一个锁，以保护控制台驱动程序的数据结构免受并发访问。这里有三个并发危险：两个在不同CPU上的进程可能同时调用consoleread；当某个CPU已经在consoleread内部执行时，硬件可能会要求该CPU传递控制台（实际上是UART）中断；当consoleread正在执行时，硬件可能会在另一个CPU上传递控制台中断。这些危险可能导致竞争或死锁。第6章探讨了这些问题以及锁如何解决它们。

并发在驱动程序中需要谨慎处理的另一种方式是，一个进程可能正在等待来自设备的输入，但表示输入到达的中断可能在另一个进程（或根本没有进程）运行时到达。因此，中断处理程序不允许考虑它们中断的进程或代码。例如，中断处理程序不能安全地使用当前进程的页表调用copyout。中断处理程序通常只做相对较少的工作（例如，只是将输入数据复制到缓冲区），并唤醒上半部分代码来完成其余工作。

## 5.4 定时器中断

xv6使用定时器中断来维护其时钟，并使其能够在计算密集型进程中进行切换；`usertrap`和`kerneltrap`中的`yield`调用导致了这种切换。定时器中断来自连接到每个RISC-V CPU的时钟硬件。xv6将此时钟硬件编程为定期中断每个CPU。

RISC-V要求定时器中断在机器模式下处理，而不是在监督模式下。RISC-V的机器模式在没有分页的情况下执行，并且具有一组独立的控制寄存器，因此在机器模式下运行普通的xv6内核代码是不现实的。因此，xv6完全独立于上述陷阱机制来处理定时器中断。

在`main`之前，在`start.c`中执行的代码设置了接收定时器中断（`kernel/start.c:63`）。其中一部分工作是将CLINT硬件（核心本地中断器）编程，使其在一定延迟后产生中断。另一部分是设置一个类似于trapframe的临时区域，以帮助定时器中断处理程序保存寄存器和CLINT寄存器的地址。最后，`start`将`mtvec`设置为`timervec`并启用定时器中断。

定时器中断可以在用户或内核代码执行的任何时刻发生；内核无法在关键操作期间禁用定时器中断。因此，定时器中断处理程序必须以保证不干扰被中断的内核代码的方式完成其工作。基本策略是让处理程序要求RISC-V引发“软件中断”，然后立即返回。RISC-V使用普通的陷阱机制将软件中断传递给内核，并允许内核禁用它们。可以在`devintr`（`kernel/trap.c:205`）中看到处理由定时器中断生成的软件中断的代码。

机器模式的定时器中断处理程序是`timervec`（`kernel/kernelvec.S:95`）。它将一些寄存器保存在`start`准备的临时区域中，告诉CLINT何时生成下一个定时器中断，要求RISC-V引发软件中断，恢复寄存器，然后返回。定时器中断处理程序中没有C代码。

## 5.5 现实世界

xv6允许在内核执行时以及执行用户程序时发生设备和定时器中断。定时器中断会强制从定时器中断处理程序进行线程切换（调用yield），即使在内核中执行也是如此。能够在内核线程之间公平地时间分片CPU是很有用的，如果内核线程有时花费大量时间进行计算而不返回用户空间的话。然而，内核代码需要意识到它可能会被暂停（由于定时器中断）并在稍后在不同的CPU上恢复，这给xv6带来了一些复杂性（参见第6.6节）。如果设备和定时器中断仅在执行用户代码时发生，内核可能会变得更简单一些。

在典型的计算机上，以完整功能支持所有设备是一项巨大的工作，因为设备种类繁多，功能丰富，且设备与驱动程序之间的协议可能复杂且文档不全。在许多操作系统中，驱动程序的代码量超过了核心内核。

UART驱动程序通过读取UART控制寄存器一次获取一个字节的数据；这种模式称为程序I/O，因为软件在驱动数据传输。程序I/O很简单，但在高数据速率下速度太慢，无法使用。需要高速传输大量数据的设备通常使用直接内存访问（DMA）。DMA设备硬件直接将输入数据写入RAM，并从RAM读取输出数据。现代磁盘和网络设备使用DMA。DMA设备的驱动程序会在RAM中准备数据，然后通过单次写入控制寄存器来告知设备处理准备好的数据。

当设备需要在不可预测的时间且不频繁地引起注意时，中断是有意义的。但中断具有较高的CPU开销。因此，高速设备（如网络和磁盘控制器）使用一些技巧来减少对中断的需求。一种技巧是为一批输入或输出请求引发单个中断。另一种技巧是驱动程序完全禁用中断，并定期检查设备是否需要关注。这种技术称为轮询。如果设备操作非常快，轮询是有意义的，但如果设备大部分时间处于空闲状态，它会浪费CPU时间。一些驱动程序会根据当前设备负载在轮询和中断之间动态切换。

UART驱动程序首先将输入数据复制到内核中的缓冲区，然后再复制到用户空间。在低数据速率下这是合理的，但对于生成或消耗数据非常快的设备，这种双重复制可能会显著降低性能。一些操作系统能够直接在用户空间缓冲区和设备硬件之间移动数据，通常使用DMA。
如第1章所述，控制台对应用程序表现为一个普通文件，应用程序使用read和write系统调用来读取输入和写入输出。应用程序可能希望控制无法通过标准文件系统调用表达的设备方面（例如，启用/禁用控制台驱动程序中的行缓冲）。Unix操作系统支持ioctl系统调用来处理这些情况。

某些计算机使用场景要求系统必须在有界时间内响应。例如，在安全关键系统中，错过截止时间可能导致灾难。xv6不适合硬实时环境。用于硬实时的操作系统倾向于作为库与应用程序链接，以便进行分析以确定最坏情况下的响应时间。xv6也不适合软实时应用，当偶尔错过截止时间是可以接受的，因为xv6的调度程序过于简单，并且其内核代码路径中存在长时间禁用中断的情况。



# 第6章

# 锁

大多数内核，包括xv6，都会交错执行多个活动。交错执行的一个来源是多处理器硬件：具有多个独立执行的CPU的计算机，例如xv6的RISC-V。这些多个CPU共享物理RAM，xv6利用这种共享来维护所有CPU读写的数据结构。这种共享引发了这样的可能性：一个CPU在另一个CPU正在进行更新时读取数据结构，甚至多个CPU同时更新同一数据；如果没有精心设计，这种并行访问可能会导致错误结果或数据结构损坏。即使在单处理器上，内核也可能在多个线程之间切换CPU，导致它们的执行交错。最后，修改与某些可中断代码相同数据的设备中断处理程序可能会在错误的时间发生中断时损坏数据。“并发”一词指的是由于多处理器并行、线程切换或中断而导致多个指令流交错的情况。

 内核中充满了并发访问的数据。例如，两个CPU可以同时调用kalloc，从而同时从空闲列表的头部弹出。内核设计者喜欢允许大量并发，因为这可以通过并行提高性能，并增加响应性。然而，因此内核设计者必须在存在这种并发的情况下说服自己代码的正确性。有许多方法可以得到正确的代码，其中一些比其他方法更容易推理。旨在实现并发下正确性的策略以及支持它们的抽象被称为并发控制技术。 

xv6根据情况使用多种并发控制技术；还有更多可能的方法。本章重点介绍一种广泛使用的技术：锁。锁提供互斥，确保一次只有一个CPU可以持有锁。如果程序员将每个共享数据项与一个锁关联，并且代码在使用项时始终持有相关联的锁，那么该项将一次只能被一个CPU使用。在这种情况下，我们说锁保护了数据项。尽管锁是一种易于理解的并发控制机制，但锁的缺点是它们可能会限制性能，因为它们会将并发操作序列化。 本章其余部分解释了为什么xv6需要锁，xv6如何实现它们，以及如何使用它们。

![image-20250729204734933](C:\Users\jiawei zhu\AppData\Roaming\Typora\typora-user-images\image-20250729204734933.png)

## 6.1 竞争

作为需要锁的原因的一个例子，考虑两个进程在两个不同的CPU上调用wait，而它们的子进程已退出。wait会释放子进程的内存。因此，在每个CPU上，内核将调用kfree来释放子进程的内存页。内核分配器维护一个链表：kalloc() (kernel/kalloc.c:69) 从空闲页列表中弹出一页内存，而kfree() (kernel/kalloc.c:47) 将一页推送到空闲列表上。为了获得最佳性能，我们可能希望两个父进程的kfrees能够并行执行，而无需等待对方，但这在给定xv6的kfree实现的情况下是不正确的。 图6.1更详细地说明了这种情况：空闲页的链表位于两个CPU共享的内存中，它们使用加载和存储指令来操作列表。（实际上，处理器有缓存，但从概念上讲，多处理器系统的行为就好像只有一个共享内存。）如果没有并发请求，你可能会实现一个列表推送操作如下

![image-20250729204811267](C:\Users\jiawei zhu\AppData\Roaming\Typora\typora-user-images\image-20250729204811267.png)

![image-20250729204835359](C:\Users\jiawei zhu\AppData\Roaming\Typora\typora-user-images\image-20250729204835359.png)

​	如果单独执行，此实现是正确的。然而，如果有多个副本并发执行，代码是不正确的。如果两个CPU同时执行push，如图6.1所示，两者都可能在线15执行，然后在线16执行，这会导致一个不正确的结果，如图6.2所示。然后会有两个列表元素的next设置为list的先前值。当在线16进行两次对list的赋值时，第二次赋值将覆盖第一次；涉及第一次赋值的元素将丢失。 在线16的丢失更新是竞争的一个例子。竞争是一种内存位置被并发访问且至少有一次访问是写操作的情况。竞争通常是bug的标志，要么是丢失更新（如果访问是写操作），要么是读取了一个未完全更新的数据结构。 竞争的结果取决于编译器生成的机器代码、涉及的两个CPU的时序以及内存系统如何对它们的内存操作进行排序，这使得由竞争引起的错误难以重现和调试。例如，在调试push时添加打印语句可能会改变执行的时序，从而使竞争消失。 避免竞争的通常方法是使用锁。锁确保互斥，因此一次只有一个CPU可以执行push的敏感行；这使得上述情况不可能发生。上述代码的正确锁定版本只增加了几行（以黄色突出显示）：

![image-20250729204909224](C:\Users\jiawei zhu\AppData\Roaming\Typora\typora-user-images\image-20250729204909224.png)

![image-20250729204919391](C:\Users\jiawei zhu\AppData\Roaming\Typora\typora-user-images\image-20250729204919391.png)

acquire和release之间的指令序列通常被称为临界区。 锁通常被认为是在保护list。 当我们说锁保护数据时，我们实际上是指锁保护适用于数据的一系列不变量。不变量是跨操作维护的数据结构属性。通常，操作的正确行为取决于操作开始时不变量为真。操作可能会暂时违反不变量，但必须在结束前重新建立它们。例如，在链表的情况下，不变量是list指向列表中的第一个元素，每个元素的next字段指向下一个元素。push的实现暂时违反了这个不变量：在17行，l指向下一个列表元素，但list还没有指向l（在18行重新建立）。我们上面检查的竞争发生是因为第二个CPU执行了依赖于列表不变量的代码，而这些不变量（暂时）被违反了。正确使用锁可以确保一次只有一个CPU可以在临界区内操作数据结构，因此没有CPU会在数据结构的不变量不成立时执行数据结构操作。

你可以将锁视为将并发的临界区序列化，使它们一次一个地运行，从而保持不变量（假设临界区在隔离情况下是正确的）。你也可以将由同一锁保护的临界区视为彼此原子的，因此每个临界区只看到早期临界区的完整更改集，而永远不会看到部分完成的更新。 尽管对正确性有用，但锁本质上会限制性能。例如，如果两个进程并发调用kfree，锁将序列化两个临界区，因此在不同CPU上运行它们没有好处。如果多个进程同时想要同一个锁，我们说它们冲突，或者锁经历争用。内核设计中的一个主要挑战是避免锁争用以追求并行性。xv6在这方面做得很少，但复杂的内核会专门组织数据结构和算法以避免锁争用。 在列表示例中，内核可以为每个CPU维护一个单独的空闲列表，只有当当前CPU的列表为空且必须从另一个CPU窃取内存时才接触另一个CPU的空闲列表。其他用例可能需要更复杂的设计。 锁的放置对性能也很重要。例如，在push中将acquire提前到第13行之前是正确的。但这可能会降低性能，因为这样对malloc的调用将被序列化。“使用锁”部分提供了关于在哪里插入acquire和release调用的一些指导。



# Chapter 7

# Scheduling

任何操作系统运行的进程数通常都会超过计算机中CPU的数量，因此需要一种方案来在各个进程之间共享CPU时间。理想情况下，这种共享对用户进程来说是透明的。一种常见的方法是通过将多个进程复用到硬件CPU上，使每个进程看起来都拥有自己独立的虚拟CPU。本章将解释xv6是如何实现这种复用的。

## 7.1 多路复用

xv6 在两种情况下通过让每个 CPU 在不同进程之间切换来实现多路复用。第一，当进程等待设备或管道 I/O 完成、等待子进程退出，或调用 sleep 系统调用而进入休眠时，xv6 的 sleep 和 wakeup 机制会触发进程切换。第二，对于长时间计算而不主动休眠的进程，xv6 会定期强制进行切换，以确保公平共享 CPU。这种多路复用机制营造出一种假象：每个进程都拥有自己的 CPU，这类似于 xv6 利用内存分配器和硬件页表为每个进程营造出拥有独立内存空间的假象。

实现多路复用面临若干挑战。

* 首先，如何从一个进程切换到另一个进程？尽管上下文切换的概念很简单，但其实现代码是 xv6 中最晦涩难懂的部分之一。
* 其次，如何以对用户进程透明的方式强制进行切换？xv6 采用一种标准技术：利用硬件定时器产生的中断来驱动上下文切换。
* 第三，所有 CPU 都在相同的共享进程集合中切换，因此必须制定锁机制以避免竞争条件。
* 第四，当进程退出时，必须释放其内存和其他资源，但进程自身无法完成全部清理工作，例如它不能在仍在使用时释放自己的内核栈。
* 第五，在多核机器上，每个核心都必须记住当前正在执行的是哪个进程，以确保系统调用能够正确修改对应进程的内核状态。
* 最后，sleep 和 wakeup 机制允许一个进程主动放弃 CPU，并等待被其他进程或中断唤醒。必须小心处理，以避免因竞争条件而导致唤醒通知丢失。xv6 力求以最简单的方式解决这些问题，但即便如此，最终的代码仍然相当复杂且容易出错。

![image-20250730082812174](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20250730082812174.png)

<center>图7.1：从一个用户进程切换到另一个用户进程。在此示例中，xv6 使用一个 CPU（因此只有一个调度器线程）运行。</center>

## 7.2 Code: Context switching

图7.1 概述了从一个用户进程切换到另一个用户进程所涉及的步骤：

* 首先，通过系统调用或中断从旧进程进入内核，形成从用户态到内核态的转换；
* 接着，从旧进程的内核线程切换到当前 CPU 的调度器线程；
* 然后，再从调度器线程切换到新进程的内核线程；
* 最后，通过陷阱返回（trap return）进入新进程的用户态代码。

xv6 为每个 CPU 都维护一个专用的调度器线程（包括保存的寄存器和栈），这是因为调度器不能安全地运行在旧进程的内核栈上：如果另一个核心唤醒了该进程并开始运行，而两个核心同时使用同一个栈，将会导致灾难性后果。在本节中，我们将重点研究内核线程与调度器线程之间切换的实现机制。

在两个线程之间切换，关键在于保存旧线程的 CPU 寄存器状态，并恢复新线程之前保存的寄存器状态。由于栈指针（`s`）和程序计数器（`pc`）也被保存和恢复，CPU 将随之切换到新的栈，并执行新线程的代码。

函数 `swtch` 负责执行内核线程切换时的寄存器保存与恢复。`swtch` 本身并不直接了解“线程”的概念，它只是保存和恢复一组包含 32 个 RISC-V 寄存器的数据结构，称为“上下文”（context）。当一个进程需要放弃 CPU 时，其内核线程会调用 `swtch`，将当前上下文保存起来，并切换回调度器的上下文。每个上下文都封装在 `struct context`（定义于 `kernel/proc.h:2`）中，该结构又嵌入在进程的 `struct proc` 或 CPU 的 `struct cpu` 中。`swtch` 接收两个参数：`struct context *old` 和 `struct context *new`。它将当前 CPU 寄存器的值保存到 `old` 所指向的上下文中，然后从 `new` 所指向的上下文中恢复寄存器值，最后返回。

让我们追踪一个进程通过 `swtch` 进入调度器的过程。在第4章中我们看到，中断处理结束时的一种可能是：`usertrap` 调用 `yield`。`yield` 进而调用 `sched`，而 `sched` 再调用 `swtch`，将当前上下文保存到 `p->context`，并切换到之前保存在 `cpu->context` 中的调度器上下文（`kernel/proc.c:497`）。

`swtch`（定义于 `kernel/swtch.S:3`）仅保存被调用者保存的寄存器（callee-saved registers）；调



用者保存的寄存器（caller-saved registers）则由 C 编译器生成代码，在调用前压入栈中保存。`swtch` 知道 `struct context` 中每个寄存器字段的偏移量。它不保存程序计数器（pc），而是保存 `ra` 寄存器（返回地址寄存器），该寄存器记录了 `swtch` 被调用时的返回地址。接着，`swtch` 从 `new` 指向的上下文中恢复寄存器值，这些值是之前某次 `swtch` 调用时保存的。当 `swtch` 返回时，它会跳转到由恢复的 `ra` 寄存器所指向的指令处执行——也就是新线程上次调用 `swtch` 时的下一条指令。同时，它使用新线程的栈，因为恢复的 `sp` 指向的是新线程的栈顶。

在我们的例子中，`sched` 调用 `swtch` 切换到 `cpu->context`，即该 CPU 的调度器上下文。这个上下文是在过去某个时刻由 `scheduler` 调用 `swtch`（`kernel/proc.c:463`）时保存的，当时它正从当前进程切换出去。当我们追踪的这次 `swtch` 返回时，它并不是返回到 `sched`，而是返回到 `scheduler`，并且栈指针指向当前 CPU 的调度器栈。

## 7.3 Code: Scheduling

上一节关注了 `swtch` 的底层实现细节。现在我们将其视为一个已知功能，来观察一个进程的内核线程如何通过调度器切换到另一个进程。调度器以每个 CPU 上的一个特殊线程形式存在，这些线程都运行 `scheduler` 函数。该函数负责选择下一个要运行的进程。任何想要放弃 CPU 的进程，必须先获取自身的进程锁 `p->lock`，释放其他持有的锁，更新自身状态（`p->state`），然后调用 `sched`。你可以在 `yield`（`kernel/proc.c:503`）、`sleep` 和 `exit` 中看到这一序列。`sched` 会再次检查这些条件（`kernel/proc.c:487-492`），并验证一个推论：由于持有锁，中断必须被禁用。最后，`sched` 调用 `swtch`，将当前上下文保存到 `p->context`，并切换到 `cpu->context` 中的调度器上下文。`swtch` 返回时，是在调度器的栈上返回，就像之前 `scheduler` 中的 `swtch` 调用返回一样（`kernel/proc.c:463`）。随后，调度器继续其循环，找到一个可运行的进程，切换到它，如此循环往复。

我们刚刚看到，xv6 在调用 `swtch` 时始终持有 `p->lock`：调用 `swtch` 的代码必须已经持有该锁，而锁的控制权将传递给被切换到的代码。这种锁的使用方式在常规编程中并不常见；通常，获取锁的线程也负责释放它，这样更容易保证正确性。但在上下文切换中必须打破这一惯例，因为 `p->lock` 用于保护进程状态和上下文字段的不变性，而在执行 `swtch` 时这些不变性并不成立。例如，如果在 `swtch` 执行时不持有 `p->lock`，可能会出现这样的问题：一个 CPU 在 `yield` 将进程状态设为 RUNNABLE 之后、但 `swtch` 尚未使其停止使用内核栈之前，决定运行该进程。结果将是两个 CPU 同时操作同一个内核栈，造成混乱。

内核线程唯一放弃 CPU 的地方就是 `sched`，并且它总是切换到 `scheduler` 中的同一位置，而 `scheduler`（几乎）总是再切换回某个之前调用过 `sched` 的内核线程。因此，如果打印出 xv6 中线程切换的代码行号，会观察到一个简单的模式：(kernel/proc.c:463)、(kernel/proc.c:497)、(kernel/proc.c:463)、(kernel/proc.c:497)，如此循环。这种通过线程切换有意地相互转移控制权的函数，有时被称为“协程”（coroutines）；在这个例子中，`sched` 和 `scheduler` 就是彼此的协程。

有一种情况例外：调度器调用 `swtch` 并不会最终进入 `sched`。`allocproc` 会将新进程的上下文中的 `ra` 寄存器设置为 `forkret`（kernel/proc.c:515），因此该进程的第一次 `swtch` 会“返回”到 `forkret` 函数的开头。`forkret` 的作用是释放 `p->lock`；否则，由于新进程需要像从 `fork` 返回一样进入用户态，它本可以直接从 `usertrapret` 开始执行。

`scheduler`（kernel/proc.c:445）运行一个循环：查找一个可运行的进程，运行它直到其主动让出 CPU，然后重复。调度器遍历进程表，寻找状态为 `RUNNABLE` 的进程。一旦找到，就设置当前 CPU 的 `c->proc` 指针指向该进程，将其状态标记为 `RUNNING`，然后调用 `swtch` 开始运行它（kernel/proc.c:458-463）。

理解调度代码结构的一种方式是：它维护一组关于每个进程的不变性（invariants），并且在这些不变性不成立时始终持有 `p->lock`。一个不变性是：如果一个进程处于 `RUNNING` 状态，那么定时器中断触发的 `yield` 必须能够安全地将其切换出去；这意味着 CPU 寄存器必须保存该进程的寄存器值（即 `swtch` 尚未将其移出），且 `c->proc` 必须指向该进程。另一个不变性是：如果一个进程处于 `RUNNABLE` 状态，那么空闲 CPU 的调度器必须能安全地运行它；这意味着 `p->context` 必须保存该进程的寄存器值（即它们不在真实寄存器中），没有 CPU 正在使用该进程的内核栈，也没有任何 CPU 的 `c->proc` 指向该进程。请注意，当 `p->lock` 被持有时，这些属性常常并不成立。

正是为了维护上述不变性，xv6 经常在一个线程中获取 `p->lock`，而在另一个线程中释放它。例如，在 `yield` 中获取锁，在 `scheduler` 中释放锁。一旦 `yield` 开始将一个运行中的进程状态改为 `RUNNABLE`，锁就必须一直持有，直到不变性恢复为止：最早可以安全释放锁的时机是在 `scheduler`（在其自己的栈上运行）清空 `c->proc` 之后。类似地，一旦 `scheduler` 开始将一个 `RUNNABLE` 进程转为 `RUNNING`，就不能在内核线程完全运行起来之前释放锁（例如，在 `swtch` 之后，如 `yield` 中所示）。

## 7.4 Code: mycpu and myproc

xv6 经常需要获取当前进程的 `proc` 结构体指针。在单处理器系统中，可以使用一个全局变量指向当前进程。但在多核系统中，这种方法行不通，因为每个核心运行的进程可能不同。解决这一问题的方法是利用每个核心都有独立寄存器集的事实，我们可以使用其中一个寄存器来帮助查找每核的私有信息。

xv6 为每个 CPU 维护一个 `struct cpu`（kernel/proc.h:22），其中记录了当前正在该 CPU 上运行的进程（如果有）、调度器线程的保存寄存器，以及用于管理中断禁用的嵌套自旋锁计数。函数 `mycpu`（kernel/proc.c:74）返回指向当前 CPU 的 `struct cpu` 的指针。RISC-V 为每个 CPU 分配一个 hartid（硬件线程 ID）。xv6 确保每个 CPU 在内核态运行时，其 `tp` 寄存器中始终保存着该 CPU 的 hartid。这样，`mycpu` 就可以通过 `tp` 寄存器作为索引，在一个 `cpu` 结构体数组中找到对应项。

确保每个 CPU 的 `tp` 寄存器始终保存其 hartid 略显复杂。`start` 在 CPU 启动早期（仍处于机器模式时）就设置了 `tp` 寄存器（kernel/start.c:51）。`usertrapret` 会在 trampoline 页中保存 `tp`，因为用户进程可能会修改该寄存器。最后，`uservec` 在从用户态进入内核态时恢复这个保存的 `tp` 值（kernel/trampoline.S:77）。编译器保证不会使用 `tp` 寄存器。如果 xv6 能够在需要时直接向 RISC-V 硬件查询当前的 hartid，那将更加方便。但 RISC-V 只允许在机器模式（machine mode）下执行此操作，而不允许在监管模式（supervisor mode）下进行。

函数 `cpuid` 和 `mycpu` 的返回值是脆弱的：如果此时发生定时器中断，导致当前线程让出 CPU 并迁移到另一个 CPU 上，那么之前返回的值就不再正确。为避免这个问题，xv6 要求调用者在调用这些函数时必须先禁用中断，并在使用完返回的 `struct cpu` 后才能重新启用中断。

函数 `myproc`（`kernel/proc.c:83`）返回当前 CPU 上正在运行的进程的 `struct proc` 指针。`myproc` 首先禁用中断，调用 `mycpu`，从返回的 `struct cpu` 中取出当前进程指针（`c->proc`），然后重新启用中断。即使之后中断被重新开启，`myproc` 返回的 `struct proc` 指针仍然是安全可用的：因为即使定时器中断导致该进程被调度到另一个 CPU 上运行，其 `struct proc` 指针仍然指向同一个进程结构体。

## 7.5 睡眠与唤醒（Sleep and wakeup）

调度和锁机制有助于隐藏一个线程对另一个线程的影响，但我们还需要一些抽象机制，使线程能够有意地进行交互。例如，xv6 中管道的读取方可能需要等待写入进程产生数据；父进程调用 `wait` 可能需要等待子进程退出；一个从磁盘读取数据的进程也需要等待磁盘硬件完成读取操作。

在这些情况下（以及其他许多场景中），xv6 内核使用一种称为“睡眠（sleep）”和“唤醒（wakeup）”的机制。`sleep` 允许一个内核线程等待某个特定事件的发生；另一个线程可以在事件发生时调用 `wakeup`，通知正在等待该事件的线程恢复执行。`sleep` 和 `wakeup` 通常被称为“序列协调”或“条件同步”机制。

`sleep` 和 `wakeup` 提供了一个相对底层的同步接口。为了说明它们在 xv6 中的工作方式，我们将使用它们构建一个更高级的同步机制——信号量（semaphore）[5]，用于协调生产者和消费者（尽管 xv6 本身并未使用信号量）。信号量维护一个计数器，并提供两个操作：

- “V” 操作（由生产者调用）：将计数器加一。
- “P” 操作（由消费者调用）：等待计数器大于零，然后将其减一并返回。

如果只有一个生产者线程和一个消费者线程，它们运行在不同的 CPU 上，并且编译器没有进行过于激进的优化，那么下面的实现将是正确的：

```c
struct semaphore {
    struct spinlock lock;
    int count;
};

void
V(struct semaphore *s)
{
    acquire(&s->lock);
    s->count +=1;
    release(&s->lock);
}

void
P(struct semaphore *s)
{
    while(s->count == 0)
        ;
    acquire(&s->lock);
    s->count -= 1;
    release(&s->lock);
}
```

上面的实现效率很低。如果生产者很少执行操作，消费者将大部分时间花费在一个 while 循环中自旋，不断检查计数器是否变为非零。此时，消费者的 CPU 完全可以去做更有意义的工作，而不是通过反复轮询 `s->count` 来忙等（busy waiting）。

为了避免忙等，我们需要一种机制，让消费者能够主动让出 CPU，并仅在 V 操作增加计数器后才恢复执行。

以下是一个朝此方向改进的尝试，但正如我们将看到的，它仍不足够。我们设想有一对系统调用：`sleep` 和 `wakeup`，其工作方式如下：

- `sleep(chan)` 在一个任意值 `chan` 上睡眠，这个值称为“等待通道”（wait channel）。`sleep` 会将调用进程置于睡眠状态，并释放 CPU 以供其他任务使用。
- `wakeup(chan)` 会唤醒所有正在 `chan` 上睡眠的进程（如果有的话），使它们的 `sleep` 调用返回。如果没有进程在 `chan` 上等待，则 `wakeup` 不做任何事。

我们可以修改信号量的实现，使其使用 `sleep` 和 `wakeup`（修改部分以黄色高亮显示）：

> 💡 **注意**：以下代码中，`wakeup(s)` 和 `sleep(s)` 是关键的同步原语调用，用于进程阻塞与唤醒。

```c
void
V(struct semaphore *s)
{
    acquire(&s->lock);
    s->count += 1;
    wakeup(s);  // 🟡 【唤醒操作】此处为 wakeup 调用
    release(&s->lock);
}

void
P(struct semaphore *s)
{
    while(s->count == 0)
        sleep(s);  // 🟡 【阻塞操作】此处为 sleep 调用
    acquire(&s->lock);
    s->count -= 1;
    release(&s->lock);
}
```

现在，P 操作会主动释放 CPU 而不是忙等，这一点很好。然而，事实证明，若想使用这种接口设计 sleep 和 wakeup 机制，同时又避免所谓的“丢失唤醒问题”，并非易事。假设 P 操作在第 212 行发现 `s->count == 0`。就在 P 执行完第 212 行但尚未执行第 213 行的间隙，另一个 CPU 上的 V 操作运行了：它将 `s->count` 改为非零值，并调用 `wakeup`。但此时还没有进程在睡眠，因此 `wakeup` 找不到等待者，什么也不做。随后，P 继续执行到第 213 行，调用 `sleep` 并进入睡眠状态。

这就产生了一个严重问题：P 正在睡眠，等待一个早已发生的 V 操作。除非生产者再次调用 V，否则消费者将永远等待下去——即使此时计数器已经是非零值。

这个问题的根源在于：P 只有在 `s->count == 0` 时才应睡眠这一不变性（invariant），被 V 操作在“错误的时机”打断而遭到破坏。

一种错误的保护该不变性的方法是，将 P 操作中的加锁操作（如下方黄色高亮部分）提前，使得对计数器的检查和调用 `sleep` 成为一个原子操作：

```c
void
V(struct semaphore *s)
{
    acquire(&s->lock);
    s->count += 1;
    wakeup(s);  
    release(&s->lock);
}

void
P(struct semaphore *s)
{
    acquire(&s->lock);// 🟡 
    while(s->count == 0)
        sleep(s);
    s->count -= 1;
    release(&s->lock);
}
```

人们可能会期望这个版本的 P 操作能够避免丢失唤醒问题，因为锁的存在阻止了 V 操作在第 313 行和第 314 行之间执行。锁确实起到了这个作用，但它也导致了死锁：P 在睡眠时仍然持有锁，因此 V 操作将因无法获取锁而永远阻塞。

我们将通过修改 `sleep` 的接口来修复上述方案：调用者必须将保护条件的锁作为参数传递给 `sleep`，这样 `sleep` 可以在将调用进程标记为“已睡眠”并将其挂到睡眠通道上之后，释放该锁。这样一来，如果此时有并发的 V 操作执行，它就必须等待 P 完成进入睡眠状态的过程，从而确保随后的 `wakeup` 能够发现正在等待的消费者并将其唤醒。当消费者被唤醒后，`sleep` 会在返回前重新获取该锁。

我们新的、正确的 `sleep`/`wakeup` 方案使用方式如下（修改部分以黄色高亮显示）：

```c
void
V(struct semaphore *s)
{
    acquire(&s->lock);
    s->count += 1;
    wakeup(s);  
    release(&s->lock);
}

void
P(struct semaphore *s)
{
    acquire(&s->lock);
    while(s->count == 0)
        sleep(s, &s->lock);// 🟡
    s->count -= 1;
    release(&s->lock);
}
```

P 持有 `s->lock` 这一事实，阻止了 V 在 P 检查 `s->count` 和调用 `sleep` 之间唤醒它。然而需要注意的是，我们必须让 `sleep` 能够原子地释放 `s->lock` 并将消费者进程置为睡眠状态，否则仍可能导致唤醒丢失。

## 7.6 代码：睡眠与唤醒

xv6 的 `sleep`（kernel/proc.c:536）和 `wakeup`（kernel/proc.c:567）提供了上一节示例中所示的接口，其实现方式以及使用规则确保不会发生“唤醒丢失”问题。其基本思想是：`sleep` 将当前进程标记为 SLEEPING 状态，然后调用 `sched` 释放 CPU；而 `wakeup` 则在进程表中查找在指定等待通道上睡眠的进程，并将其状态改为 RUNNABLE。`sleep` 和 `wakeup` 的调用者可以使用任意双方都方便的数值作为通道。xv6 通常使用与等待操作相关的内核数据结构的地址作为通道。

`sleep` 首先获取当前进程的 `p->lock`（`kernel/proc.c:547`）。此时，即将进入睡眠的进程同时持有 `p->lock` 和调用者传入的条件锁 `lk`。在调用者（如上例中的 P 操作）中持有 `lk` 是必要的：它确保了其他进程（如执行 V 操作的进程）无法开始调用 `wakeup(chan)`。现在 `sleep` 已经持有了 `p->lock`，此时释放 `lk` 是安全的：其他进程可能开始调用 `wakeup(chan)`，但 `wakeup` 必须先获取 `p->lock`，因此它会一直等待，直到 `sleep` 完成将进程置为睡眠状态的过程。这就保证了 `wakeup` 不会错过正在睡眠的进程。

现在 `sleep` 只持有 `p->lock`，它可以安全地将进程置为睡眠状态：记录睡眠通道（`chan`），将进程状态改为 SLEEPING，并调用 `sched`（kernel/proc.c:551–554）。稍后我们将看到，为什么在进程被标记为 SLEEPING 之后才释放 `p->lock`（由 `scheduler` 完成）是至关重要的。

在某个时刻，某个进程会获取条件锁，设置被等待的条件，并调用 `wakeup(chan)`。**关键在于，调用 `wakeup` 时必须持有条件锁**。`wakeup` 遍历整个进程表(`kernel/proc.c:567`)，对每个检查的进程都获取其 `p->lock`，原因有两个：一是可能需要修改该进程的状态，二是 `p->lock` 能确保 `sleep` 和 `wakeup` 不会相互错过。当 `wakeup` 发现某个进程状态为 SLEEPING 且其 `chan` 与传入的通道匹配时，就将其状态改为 RUNNABLE。下一次调度器运行时，就会发现该进程已就绪，可以被调度执行。

为什么 `sleep` 和 `wakeup` 的加锁规则能确保睡眠进程不会错过唤醒？因为在检查条件之前到被标记为 SLEEPING 之后的整个时间段内，睡眠进程始终持有条件锁、`p->lock` 或两者。而调用 `wakeup` 的进程在其循环中也会持有这两个锁。因此，唤醒者（waker）要么在消费者线程检查条件之前就使条件成立；要么在消费者线程被明确标记为 SLEEPING 之后才执行 `wakeup` 的检查。在这两种情况下，`wakeup` 都能看到正在睡眠的进程并将其唤醒（除非有其他事件先将其唤醒）。

有时，多个进程会同时在同一个通道上睡眠；例如，多个进程同时从一个管道读取数据。一次 `wakeup` 调用会唤醒所有这些进程。其中只有一个进程能最先运行并获取 `sleep` 所用的锁（对管道而言，是获取管道锁），然后读取管道中的数据。其他进程醒来后会发现数据已被读走，无数据可读。从它们的角度看，这次唤醒是“虚假的”（spurious），因此它们必须再次进入睡眠。正因如此，`sleep` 总是被放在一个循环中调用，以反复检查条件。

即使两个不同的 `sleep`/`wakeup` 使用了相同的通道，也不会造成严重问题：它们可能会收到虚假唤醒，但通过上述循环检查机制可以容忍这一问题。`sleep`/`wakeup` 的魅力在于它既轻量（无需创建专门的数据结构作为睡眠通道），又提供了间接性（调用者无需知道具体与哪个进程交互）。

## 7.7 Code：pipe

一个更复杂的使用 `sleep` 和 `wakeup` 来同步生产者与消费者的例子是 xv6 的管道（pipe）实现。我们在第1章中了解了管道的接口：写入管道一端的数据被复制到内核缓冲区中，之后可以从另一端读取。后续章节将探讨围绕管道的文件描述符支持，但我们现在先来看 `pipewrite` 和 `piperead` 的实现。

每个管道由一个 `struct pipe` 表示，其中包含一个锁和一个数据缓冲区。字段 `nread` 和 `nwrite` 分别记录从缓冲区读取和写入的总字节数。缓冲区是循环使用的：在 `buf[PIPESIZE-1]` 之后写入的下一个字节将存入 `buf[0]`。但计数本身不循环。这种设计使得实现可以区分缓冲区满（`nwrite == nread + PIPESIZE`）和空（`nwrite == nread`）的情况，但这也意味着访问缓冲区时必须使用 `buf[nread % PIPESIZE]` 而不是直接使用 `buf[nread]`（对 `nwrite` 同理）。

假设在两个不同的 CPU 上同时调用 `piperead` 和 `pipewrite`。`pipewrite`（`kernel/pipe.c:77`）首先获取管道锁，该锁保护计数、数据及其相关不变性。`piperead`（kernel/pipe.c:106）随后也尝试获取该锁，但因锁已被占用而无法成功。它在 `acquire`（kernel/spinlock.c:22）中自旋等待锁释放。在此期间，`pipewrite` 遍历待写入的字节（`addr[0..n-1]`），逐个将它们加入管道（kernel/pipe.c:95）。在此过程中，可能发生缓冲区已满的情况（kernel/pipe.c:88）。此时，`pipewrite` 调用 `wakeup` 通知任何正在睡眠的读取者：缓冲区中已有数据可读；然后它在 `&pi->nwrite` 上调用 `sleep`，等待有读取者从缓冲区取出一些数据。`sleep` 在将写入进程置为睡眠状态的同时，会释放 `pi->lock`。

现在 `pi->lock` 可用，`piperead` 成功获取锁并进入临界区：它发现 `pi->nread != pi->nwrite`（kernel/pipe.c:113）（因为 `pipewrite` 是在 `pi->nwrite == pi->nread + PIPESIZE` 时进入睡眠的），于是进入 `for` 循环，从管道中复制数据（kernel/pipe.c:120），并将 `nread` 增加已复制的字节数。此时缓冲区腾出了空间，可供写入，因此 `piperead` 在返回前调用 `wakeup`（kernel/pipe.c:127）唤醒任何正在等待的写入者。`wakeup` 找到在 `&pi->nwrite` 上睡眠的进程（即之前因缓冲区满而暂停的 `pipewrite` 进程），将其状态标记为 RUNNABLE。

管道代码为读取者和写入者使用了不同的睡眠通道（`pi->nread` 和 `pi->nwrite`）；这在有大量读写者等待同一管道的罕见情况下可能提升系统效率。管道代码在循环中调用 `sleep` 以检查睡眠条件；如果存在多个读取者或写入者，除第一个被唤醒的进程外，其余进程会发现条件仍不满足，于是再次进入睡眠。



## 7.8 代码：wait、exit 和 kill

`sleep` 和 `wakeup` 可用于多种等待场景。一个在第1章中介绍的有趣例子是子进程的 `exit` 与其父进程的 `wait` 之间的交互。当子进程终止时，其父进程可能已经在 `wait` 中睡眠，也可能正在执行其他任务；在后一种情况下，后续调用 `wait` 时仍必须能够观察到子进程的死亡，即使该死亡发生在很久以前的 `exit` 调用中。xv6 通过 `exit` 将调用者置为 ZOMBIE 状态来记录其死亡，该状态会一直保持，直到父进程的 `wait` 发现它，将其状态改为 UNUSED，复制其退出状态，并将子进程的 PID 返回给父进程。

如果父进程先于子进程退出，系统会通过 `reparent` 机制将子进程交给 `init` 进程（PID 为 1），而 `init` 会持续调用 `wait` 来回收所有孤儿进程。因此，每个子进程最终都有一个父进程来清理其资源。一个挑战是避免在父进程与子进程同时调用 `wait` 和 `exit`，或多个 `exit` 同时发生时出现竞争条件或死锁。

`wait`（`kernel/proc.c:391`）首先获取全局锁 `wait_lock`。原因是 `wait_lock` 作为“条件锁”，确保父进程不会错过退出子进程发出的 `wakeup` 通知。随后，`wait` 遍历进程表。如果发现某个子进程处于 ZOMBIE 状态，它将释放该子进程的资源及其 `proc` 结构体，将子进程的退出状态复制到 `wait` 提供的地址（如果非空），并返回该子进程的 PID。如果 `wait` 找到了子进程但它们尚未退出，它会调用 `sleep` 在 `wait_lock` 上等待子进程退出（`kernel/proc.c:433`），之后再次扫描。`wait` 通常同时持有两个锁：`wait_lock` 和某个子进程的 `pp->lock`；为避免死锁，加锁顺序必须是先 `wait_lock`，再 `pp->lock`。

`exit`（`kernel/proc.c:347`）记录退出状态，释放部分资源，调用 `reparent` 将其子进程交给 `init`，唤醒父进程（以防其正在 `wait`），将自身标记为 ZOMBIE 状态，并永久让出 CPU。在整个过程中，`exit` 同时持有 `wait_lock` 和 `p->lock`。它持有 `wait_lock` 是因为这是 `wakeup(p->parent)` 的条件锁，防止父进程在 `wait` 中错过唤醒信号。`exit` 还必须持有 `p->lock`，以防止父进程在子进程尚未完成 `swtch` 切换前就观察到其状态已变为 ZOMBIE。为避免死锁，`exit` 以与 `wait` 相同的顺序获取锁。

表面上看，`exit` 在将状态设为 ZOMBIE 之前就唤醒父进程似乎不正确，但实际上这是安全的：尽管 `wakeup` 可能使父进程开始运行，但 `wait` 中的循环在子进程的 `p->lock` 被调度器释放之前无法检查该子进程的状态。因此，`wait` 只有在 `exit` 已经设置 ZOMBIE 状态（kernel/proc.c:379）并完成所有清理之后，才能访问该进程。

与 `exit` 允许进程自行终止不同，`kill`（kernel/proc.c:586）允许一个进程请求终止另一个进程。如果 `kill` 直接销毁目标进程，实现将非常复杂，因为目标进程可能正在另一个 CPU 上运行，甚至可能正处于对内核数据结构进行关键更新的中间阶段。因此，`kill` 的操作非常轻量：它只是设置目标进程的 `p->killed` 标志，如果目标正在睡眠，则调用 `wakeup` 将其唤醒。

最终，当目标进程进入或退出内核时，`usertrap` 中的代码会检查 `p->killed` 标志（通过调用 `killed` 函数，kernel/proc.c:615），若标志已设置，则调用 `exit`。如果目标进程正在用户态运行，它很快会因系统调用或定时器（或其他设备）中断而进入内核。

如果目标进程正在 `sleep`，`kill` 调用的 `wakeup` 会使它从 `sleep` 返回。这可能带来风险，因为被等待的条件可能尚未满足。然而，xv6 中所有 `sleep` 调用都包裹在 `while` 循环中，`sleep` 返回后会重新检查条件。有些 `sleep` 循环还会在循环中检查 `p->killed`，若标志已设置，则放弃当前操作。这种放弃仅在逻辑上安全时才进行。例如，管道的读写代码在 `killed` 标志被设置时直接返回；最终控制流会回到陷阱处理程序（trap），再次检查 `killed` 并调用 `exit`。

某些 xv6 的 `sleep` 循环不检查 `p->killed`，因为这些代码正处于一个多步骤的、应保持原子性的系统调用中。例如 virtio 磁盘驱动（kernel/virtio_disk.c:285）就不检查 `killed`，因为一次磁盘操作可能是多个必须全部完成才能保证文件系统一致性的写操作之一。在这种情况下，即使进程被 `kill`，也必须等到当前 I/O 操作完成、系统调用结束，`usertrap` 再检查 `killed` 标志后才会真正退出。



## 7.9 进程锁（Process Locking）

与每个进程关联的锁（`p->lock`）是 xv6 中最复杂的锁。理解 `p->lock` 的一种简单方式是：在读取或写入以下 `struct proc` 字段时，必须持有该锁：`p->state`、`p->chan`、`p->killed`、`p->xstate` 和 `p->pid`。这些字段可能被其他进程或其他核心上的调度器线程访问，因此自然需要通过锁来保护。

然而，`p->lock` 的大多数用途实际上是在保护 xv6 进程数据结构和算法中更高层次的属性。以下是 `p->lock` 所承担的全部职责：

- **结合 `p->state`**，防止在为新进程分配 `proc[]` 槽位时发生竞争条件。
- 在进程创建或销毁过程中，通过持有锁将其对系统“隐藏”起来，防止其他代码在初始化未完成时访问它。
- 防止父进程的 `wait` 系统调用过早地回收一个已将其状态设为 ZOMBIE 但尚未让出 CPU 的子进程。
- 防止另一个核心的调度器在某个进程将其状态设为 RUNNABLE 后、但尚未完成 `swtch` 切换前，就决定调度该进程运行。
- 确保只有一个核心的调度器能够决定运行某个 RUNNABLE 状态的进程。
- 防止定时器中断在进程正处于 `swtch` 切换过程中时触发其让出 CPU。
- 与条件锁（condition lock）配合，防止 `wakeup` 在 `sleep` 调用尚未完成让出 CPU 时遗漏正在睡眠的进程。
- 防止 `kill` 系统调用在检查 `p->pid` 和设置 `p->killed` 之间，目标进程恰好退出并被重新分配给新进程。
- 保证 `kill` 对 `p->state` 的检查和修改操作是原子的。

字段 `p->parent` 并不由 `p->lock` 保护，而是由一个全局锁 `wait_lock` 保护。只有进程的父进程会修改 `p->parent`，但该字段会被进程自身以及其他进程（在查找子进程时）读取。`wait_lock` 的主要作用是作为 `wait` 系统调用在等待任意子进程退出时的“条件锁”。一个正在退出的子进程会持有 `wait_lock` 或 `p->lock`，直到它完成以下操作：将自身状态设为 ZOMBIE、唤醒父进程、并让出 CPU。

此外，`wait_lock` 还用于串行化父进程和子进程的并发退出操作，确保 init 进程（作为孤儿进程的继承者）能够被正确唤醒。之所以使用全局锁而不是每个父进程一个锁，是因为在获取锁之前，进程无法确定自己的父进程是谁——因此无法提前获取对应父进程的锁。